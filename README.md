# TransFace-ByteFace
* Code for the following papers:

**(1)** [[ICCV-2023] TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective](https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html). (Conference version)

**(2)** TransFace++: Rethinking the Face Recognition Paradigm with a Focus on Efficiency, Security, and Precision. (Under Review).

Codes for TransFace and TransFace++ models are respectively in folders [TransFace](https://github.com/DanJun6737/TransFace_pp/tree/main/TransFace) and [TransFace++](https://github.com/DanJun6737/TransFace_pp/tree/main/TransFace%2B%2B).

## Citation
* If you find it helpful for you, please cite our paper
```
@inproceedings{dan2023transface,
  title={TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective},
  author={Dan, Jun and Liu, Yang and Xie, Haoyu and Deng, Jiankang and Xie, Haoran and Xie, Xuansong and Sun, Baigui},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20642--20653},
  year={2023}
}
```

## Acknowledgments
We thank Insighface for the excellent [code base](https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch).
